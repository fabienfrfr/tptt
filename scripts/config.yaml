model_configs:
  llama:
    base_model_name: "meta-llama/Llama-3.2-1B"
    base_tokenizer_name: "meta-llama/Llama-3.2-1B"
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
    quantization: false

  olmo:
    base_model_name: "allenai/OLMo-1B-hf"
    base_tokenizer_name: "allenai/OLMo-1B-hf"
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
    quantization: false

  elm:
    base_model_name: "apple/OpenELM-1_1B"
    base_tokenizer_name: "meta-llama/Llama-2-7b-hf"
    target_modules:
      - "qkv_proj"
      - "out_proj"
    quantization: false

  qwen:
    base_model_name: "Qwen/Qwen2.5-1.5B"
    base_tokenizer_name: "Qwen/Qwen2.5-1.5B"
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
    quantization: false
    task_type: "causal-lm"

  mistral:
    base_model_name: "mistralai/Mistral-7B-v0.3"
    base_tokenizer_name: "mistralai/Mistral-7B-v0.3"
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
    quantization: true

  moe:
    base_model_name: "allenai/OLMoE-1B-7B-0924"
    base_tokenizer_name: "allenai/OLMoE-1B-7B-0924"
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
    quantization: true

  diffusion:
    base_model_name: "Dream-org/Dream-v0-Base-7B"
    base_tokenizer_name: "Dream-org/Dream-v0-Base-7B"
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
    quantization: true

linear_config:
  delta_rule:
    linear_checkpointing: true
    linear_precision: "bfloat16"
  delta_product:
    linear_checkpointing: true

callback_configs:
  default:
    step_size: 1000

  constant:
    step_size: 1000

  switch:
    step_size: 1000
    random_seed: 42

training_configs:
  testing:
    batch_size: 1
    max_length: 128
    padding: "max_length"

  small:
    batch_size: 4
    max_length: 384
    padding: "longest"

  medium:
    batch_size: 8
    max_length: 512
    padding: "max_length"

  large:
    batch_size: 16
