{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f958a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_rule max abs diff: 3.5762786865234375e-07\n",
      "GLA max abs diff: 6.677595138549805\n",
      "S0.unsqueeze(2): torch.Size([2, 3, 1, 4, 4])\n",
      "prod_S0.unsqueeze(-1): torch.Size([2, 3, 8, 1, 1])\n",
      "o: torch.Size([2, 3, 8, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def delta_rule_recurrent(v, eta, h0=None):\n",
    "    B, H, N, D = v.shape\n",
    "    if h0 is None:\n",
    "        h = torch.zeros(B, H, D, dtype=v.dtype, device=v.device)\n",
    "    else:\n",
    "        h = h0\n",
    "    outs = []\n",
    "    for t in range(N):\n",
    "        h = (1 - eta[:, :, t, :]) * h + eta[:, :, t, :] * v[:, :, t, :]\n",
    "        outs.append(h.unsqueeze(2))\n",
    "    return torch.cat(outs, dim=2)\n",
    "\n",
    "def delta_rule_closed_form(v, eta, h0=None):\n",
    "    B, H, N, D = v.shape\n",
    "    one_minus_eta = 1 - eta\n",
    "    log_1m_eta = torch.log(one_minus_eta + 1e-8)\n",
    "    log_cumsum = torch.cumsum(log_1m_eta, dim=2)\n",
    "    log_cumsum_t = log_cumsum.unsqueeze(3)\n",
    "    log_cumsum_j = log_cumsum.unsqueeze(2)\n",
    "    prod = torch.exp(log_cumsum_t - log_cumsum_j)\n",
    "    mask = torch.tril(torch.ones(N, N, device=v.device), diagonal=0).unsqueeze(0).unsqueeze(0).unsqueeze(-1)\n",
    "    prod = prod * mask\n",
    "    ev = eta * v\n",
    "    ev_j = ev.unsqueeze(2)\n",
    "    h = torch.sum(prod * ev_j, dim=3)\n",
    "    if h0 is not None:\n",
    "        prod_h0 = torch.exp(log_cumsum)\n",
    "        h = h + prod_h0 * h0.unsqueeze(2)\n",
    "    return h\n",
    "\n",
    "def gla_recurrent(q, k, v, lambd, S0=None):\n",
    "    B, H, N, D = q.shape\n",
    "    if S0 is None:\n",
    "        S = torch.zeros(B, H, D, D, dtype=q.dtype, device=q.device)\n",
    "    else:\n",
    "        S = S0\n",
    "    outs = []\n",
    "    for t in range(N):\n",
    "        kvT = torch.einsum('bhd,bhe->bhde', k[:, :, t, :], v[:, :, t, :])\n",
    "        lmbd = lambd[:, :, t, :].reshape(B, H, 1, 1)\n",
    "        S = lmbd * S + (1 - lmbd) * kvT\n",
    "        o = torch.einsum('bhd,bhde->bhe', q[:, :, t, :], S)\n",
    "        outs.append(o.unsqueeze(2))\n",
    "    return torch.cat(outs, dim=2)\n",
    "\n",
    "def gla_closed_form(q, k, v, lambd, S0=None):\n",
    "    B, H, N, D = q.shape\n",
    "    one_minus_lambd = 1 - lambd  # [B, H, N, 1]\n",
    "    prod = torch.cumprod(lambd.flip(dims=[2]), dim=2).flip(dims=[2])\n",
    "    prod = torch.cat([prod[:, :, 1:, :], torch.ones_like(prod[:, :, :1, :])], dim=2)\n",
    "    weights = one_minus_lambd * prod  # [B, H, N, 1]\n",
    "    kvT = torch.einsum('b h n d, b h n e -> b h n d e', k, v)  # [B, H, N, D, D]\n",
    "    S = torch.cumsum(weights.unsqueeze(-1) * kvT, dim=2)  # [B, H, N, D, D]\n",
    "    if S0 is not None:\n",
    "        prod_S0 = torch.cumprod(lambd, dim=2)  # [B, H, N, 1]\n",
    "        S = S + prod_S0.unsqueeze(-1) * S0.unsqueeze(2)  # [B, H, N, D, D]\n",
    "    o = torch.einsum('b h n d, b h n d e -> b h n e', q, S)\n",
    "    return o\n",
    "\n",
    "def test_equivalence():\n",
    "    torch.manual_seed(0)\n",
    "    B, H, N, D = 2, 3, 8, 4\n",
    "    v = torch.randn(B, H, N, D)\n",
    "    eta = torch.sigmoid(torch.randn(B, H, N, D))\n",
    "    h0 = torch.randn(B, H, D)\n",
    "\n",
    "    # delta_rule\n",
    "    h_recur = delta_rule_recurrent(v, eta, h0)\n",
    "    h_closed = delta_rule_closed_form(v, eta, h0)\n",
    "    print(\"delta_rule max abs diff:\", (h_recur - h_closed).abs().max().item())\n",
    "\n",
    "    # GLA\n",
    "    q = torch.randn(B, H, N, D)\n",
    "    k = torch.randn(B, H, N, D)\n",
    "    v = torch.randn(B, H, N, D)\n",
    "    lambd = torch.sigmoid(torch.randn(B, H, N, 1))\n",
    "    S0 = torch.randn(B, H, D, D)\n",
    "\n",
    "    o_recur = gla_recurrent(q, k, v, lambd, S0)\n",
    "    o_closed = gla_closed_form(q, k, v, lambd, S0)\n",
    "    print(\"GLA max abs diff:\", (o_recur - o_closed).abs().max().item())\n",
    "    # VÃ©rification des shapes :\n",
    "    print(\"S0.unsqueeze(2):\", S0.unsqueeze(2).shape)\n",
    "    print(\"prod_S0.unsqueeze(-1):\", torch.cumprod(lambd, dim=2).unsqueeze(-1).shape)\n",
    "    print(\"o:\", o_closed.shape)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_equivalence()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
