{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python -V\n!pip list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:32:09.546298Z","iopub.status.idle":"2025-05-22T21:32:09.546629Z","shell.execute_reply.started":"2025-05-22T21:32:09.546467Z","shell.execute_reply":"2025-05-22T21:32:09.546482Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q -U git+https://github.com/fabienfrfr/tptt@main","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:39:51.149318Z","iopub.execute_input":"2025-05-24T10:39:51.149957Z","iopub.status.idle":"2025-05-24T10:41:37.266883Z","shell.execute_reply.started":"2025-05-24T10:39:51.149934Z","shell.execute_reply":"2025-05-24T10:41:37.265990Z"}},"outputs":[{"name":"stdout","text":"  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for tptt (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding, DataCollatorForLanguageModeling, TrainerCallback\nfrom datasets import load_dataset\nimport tptt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:41:37.268560Z","iopub.execute_input":"2025-05-24T10:41:37.268797Z","iopub.status.idle":"2025-05-24T10:42:14.336321Z","shell.execute_reply.started":"2025-05-24T10:41:37.268774Z","shell.execute_reply":"2025-05-24T10:42:14.335762Z"}},"outputs":[{"name":"stderr","text":"2025-05-24 10:41:54.872278: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748083315.312462      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748083315.427383      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Step 1: Load configuration and initialize the TPTT model\n# Using a pretrained backbone (TinyLlama in this example)\nconfig = tptt.TpttConfig(base_model_name=\"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\")#, mag_weight=0.1, inject_liza=False)\nmodel = tptt.TpttModel(config)\n\n# Step 2: (Optional) Inject LoRA adapters for parameter-efficient fine-tuning\nmodel.add_lora()\n\n# Step 3: Load the tokenizer corresponding to the base model\ntokenizer = AutoTokenizer.from_pretrained(config.base_tokenizer_name)\n# Ensure the tokenizer has a padding token for batching\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token or \"[PAD]\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:42:14.336963Z","iopub.execute_input":"2025-05-24T10:42:14.337463Z","iopub.status.idle":"2025-05-24T10:42:34.539123Z","shell.execute_reply.started":"2025-05-24T10:42:14.337443Z","shell.execute_reply":"2025-05-24T10:42:34.537698Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/560 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9bfb39e933d40aabd23ec890563a066"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe88c2bf77a8407185fc392009635994"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/129 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f34f6c36b9054868b495b5c51806144c"}},"metadata":{}},{"name":"stdout","text":"trainable params: 2,252,800 || all params: 1,102,301,184 || trainable%: 0.2044\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33798bc5ab2c48ac941250b58e7648da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9ec96c3d70e4ed5889da3cbd4d73faa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54dc2a8535f045d5a78971b5bd0c248e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"263548423ada4ab8a18cd1883d48ecec"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Step 4: Prepare the training dataset\n# Here we use a small subset of the Alpaca dataset for demonstration purposes\nraw_dataset = load_dataset(\"yahma/alpaca-cleaned\")[\"train\"].select(range(100))\n\ndef preprocess_fn(samples):\n    \"\"\"\n    Tokenize the samples for causal language modeling.\n    Concatenate instruction, input, and output as needed.\n    \"\"\"\n    prompts = [\n        f\"{instr}\\n{inp}\" if inp else instr\n        for instr, inp in zip(samples[\"instruction\"], samples[\"input\"])\n    ]\n    # Optionally, append output for supervised fine-tuning\n    prompts = [f\"{p}\\n{out}\" for p, out in zip(prompts, samples[\"output\"])]\n    tokens = tokenizer(\n        prompts,\n        truncation=True,\n        max_length=256,\n        padding=\"max_length\",\n        return_attention_mask=True,\n    )\n    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n    return tokens\n\ntokenized_dataset = raw_dataset.map(\n    preprocess_fn, batched=True, remove_columns=raw_dataset.column_names\n)\n\n# Tokenize the dataset in batches and remove original columns\ntokenized_dataset = raw_dataset.map(\n    preprocess_fn, batched=True, remove_columns=raw_dataset.column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:42:34.540576Z","iopub.execute_input":"2025-05-24T10:42:34.540863Z","iopub.status.idle":"2025-05-24T10:42:37.718950Z","shell.execute_reply.started":"2025-05-24T10:42:34.540842Z","shell.execute_reply":"2025-05-24T10:42:37.718191Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/11.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc16f6eca3014bb983e6c2854a1cd8b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"alpaca_data_cleaned.json:   0%|          | 0.00/44.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bd385bbd5fa41aab9a5b3b1b36128a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4270b587e9144ba81a8d53cece0675e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca15f2841aa2448b86181a90a8769518"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"866ed43fcdc543e787e3cd715c6d02bb"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Step 5: Set up a data collator for dynamic padding during training\n#data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"max_length\")\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False,\n)\n\n\n# Step 6: Define HuggingFace TrainingArguments for reproducible training\ntraining_args = TrainingArguments(\n    output_dir=\"./tptt_output\",\n    per_device_train_batch_size=4, # per_device_train_batch_size * N GPU --> VRAM limit risk\n    num_train_epochs=10,\n    learning_rate=  5e-4, #1e-5, #2e-4, too brutal ?\n    max_grad_norm=1.0, # gradiant clipping\n    fp16=True, #fp16=True,  # Use mixed precision if supported by hardware\n    logging_steps=5,\n    save_strategy=\"epoch\",\n    report_to=\"tensorboard\",\n)\n\n# Step 7: Initialize the HuggingFace Trainer\ninitial_weight=0.01,\nfinal_weight=0.5,\ntransition_step=100,\nliza_callback = tptt.AdjustMaGWeightCallback(\n            model,\n            initial_weight=initial_weight,\n            final_weight=final_weight,\n            transition_step=transition_step,)\n\n# Trainer will automatically handle device placement (CPU/GPU)\ntrainer = Trainer(\n    model=model,#.backbone,  # Use the underlying HF model for training\n    args=training_args,\n    #label_names=[\"labels\"],  # (peft warning, but doesn't exist!)\n    train_dataset=tokenized_dataset,\n    data_collator=data_collator,\n    processing_class=tokenizer,\n    callbacks=[liza_callback],\n    #callbacks=[DebugLossCallback()],\n)\n\n# batch = next(iter(trainer.get_train_dataloader()))\n# print(\"Labels:\", batch[\"labels\"][0]) # Verify if special tokens (-100) for padding\n# print(batch.keys()) # dict_keys(['input_ids', 'attention_mask', 'labels'])\n\n# Step 8: Launch training\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:42:37.719640Z","iopub.execute_input":"2025-05-24T10:42:37.719930Z","iopub.status.idle":"2025-05-24T10:48:28.864512Z","shell.execute_reply.started":"2025-05-24T10:42:37.719902Z","shell.execute_reply":"2025-05-24T10:48:28.863662Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [130/130 05:43, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>0.867800</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.753100</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.756700</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.635800</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.710600</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.590300</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.617400</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.565700</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.485400</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.519500</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.494100</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.469200</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.480400</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.402500</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.434300</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.444400</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.342400</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.372800</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.310900</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.376800</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>0.342100</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.312000</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>0.298000</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.320700</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.310400</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.286000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=130, training_loss=0.48073567335422224, metrics={'train_runtime': 348.3308, 'train_samples_per_second': 2.871, 'train_steps_per_second': 0.373, 'total_flos': 1592471322624000.0, 'train_loss': 0.48073567335422224, 'epoch': 10.0, 'mag_weight': 0.4951})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Step 9: Prepare the model for inference\n# Move model to the desired device (e.g., \"cuda:0\" or \"cpu\") for generation\ndevice = 0 if torch.cuda.is_available() else -1\nmodel.to(f\"cuda:{device}\" if device != -1 else \"cpu\")\n#model.eval() ## fix : RuntimeError: The size of tensor a (32) must match the size of tensor b (20) at non-singleton dimension 1\nmodel.train()\n\n# Step 10: Build the inference pipeline with the correct device and tokenizer\npipe = tptt.TpttPipeline(model=model.backbone, tokenizer=tokenizer, device=device)\n\n# Step 11: Generate text from a prompt\nresult = pipe(\"Once upon a time,\", max_new_tokens=150)\nprint(result[0][\"generated_text\"])  # Print the generated text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:57:28.359998Z","iopub.execute_input":"2025-05-24T10:57:28.360732Z","iopub.status.idle":"2025-05-24T10:57:32.552719Z","shell.execute_reply.started":"2025-05-24T10:57:28.360708Z","shell.execute_reply":"2025-05-24T10:57:32.552057Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Once upon a time, there was a kingdom. It was a beautiful, majestic kingdom, with a rich history and a bright future. The people of this kingdom were free to do as they pleased, as long as they followed the rules. The kingdom was safe, secure\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Step 12: Save the trained model and tokenizer for future use or deployment\nmodel.save_pretrained(\"./my_tptt_model\")\ntokenizer.save_pretrained(\"./my_tptt_model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### DEBUG PARTS","metadata":{}},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:49:48.832110Z","iopub.execute_input":"2025-05-24T10:49:48.832419Z","iopub.status.idle":"2025-05-24T10:49:48.842958Z","shell.execute_reply.started":"2025-05-24T10:49:48.832398Z","shell.execute_reply":"2025-05-24T10:49:48.842099Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"TpttModel(\n  (backbone): PeftModelForCausalLM(\n    (base_model): LoraModel(\n      (model): LlamaForCausalLM(\n        (model): LlamaModel(\n          (embed_tokens): Embedding(32000, 2048)\n          (layers): ModuleList(\n            (0-21): 22 x LlamaDecoderLayer(\n              (self_attn): LiZAttention(\n                (base_attn): LlamaAttention(\n                  (q_proj): lora.Linear(\n                    (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=2048, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=2048, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k_proj): lora.Linear(\n                    (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=2048, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=256, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (v_proj): lora.Linear(\n                    (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=2048, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=256, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o_proj): lora.Linear(\n                    (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=2048, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=2048, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                )\n                (operator): AttentionOperator()\n                (pool_g): AdaptiveAvgPool1d(output_size=256)\n              )\n              (mlp): LlamaMLP(\n                (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n                (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n                (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n                (act_fn): SiLU()\n              )\n              (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n              (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n            )\n          )\n          (norm): LlamaRMSNorm((2048,), eps=1e-05)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"### DEBUG Callback\nclass DebugLossCallback(TrainerCallback):\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs is not None and \"loss\" in logs:\n            print(f\"[DEBUG][Callback] Step {state.global_step} loss: {logs['loss']}\")\n\nbatch = next(iter(trainer.get_train_dataloader()))\nprint(\"\\n[DEBUG] Batch keys:\", batch.keys())\nprint(\"[DEBUG] input_ids (first 10):\", batch[\"input_ids\"][0][:10])\nprint(\"[DEBUG] labels (first 10):\", batch[\"labels\"][0][:10])\nprint(\"[DEBUG] labels unique:\", torch.unique(batch[\"labels\"]))\nprint(\"[DEBUG] nb non-masked labels:\", (batch[\"labels\"] != -100).sum().item())\noutput = model(**batch)\nprint(\"[DEBUG] Forward output.loss:\", output.loss)","metadata":{"execution":{"iopub.status.busy":"2025-05-24T10:59:17.625865Z","iopub.execute_input":"2025-05-24T10:59:17.626542Z","iopub.status.idle":"2025-05-24T10:59:19.057636Z","shell.execute_reply.started":"2025-05-24T10:59:17.626517Z","shell.execute_reply":"2025-05-24T10:59:19.056715Z"},"trusted":true},"outputs":[],"execution_count":null}]}